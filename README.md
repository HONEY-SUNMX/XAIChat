# XAIChat - å¤šæ¨¡æ€ AI å¯¹è¯åº”ç”¨

åŸºäº Qwen ç³»åˆ—æ¨¡å‹çš„å¤šæ¨¡æ€ AI å¯¹è¯åº”ç”¨ï¼Œæ”¯æŒæ–‡æœ¬å¯¹è¯ã€å›¾åƒç†è§£ï¼ˆVisionï¼‰å’Œæ–‡ç”Ÿå›¾ï¼ˆText-to-Imageï¼‰åŠŸèƒ½ã€‚

## ç‰¹æ€§

- ğŸ¤– **å¤šè½®å¯¹è¯** - è‡ªåŠ¨ç»´æŠ¤å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œæ”¯æŒæ€è€ƒæ¨¡å¼å±•ç¤ºæ¨ç†è¿‡ç¨‹
- ğŸ‘ï¸ **å›¾åƒç†è§£** - åŸºäº Qwen2-VL çš„è§†è§‰é—®ç­”èƒ½åŠ›
- ğŸ¨ **æ–‡ç”Ÿå›¾** - åŸºäº LCM çš„å¿«é€Ÿå›¾åƒç”Ÿæˆ
- âš¡ **æµå¼è¾“å‡º** - æ‰“å­—æœºæ•ˆæœå®æ—¶æ˜¾ç¤º
- ğŸŒ **Web UI** - åŸºäº React çš„ç°ä»£åŒ– Web ç•Œé¢
- ğŸ”Œ **REST API** - åŸºäº FastAPI çš„å®Œæ•´ API æœåŠ¡
- ğŸ’» **CLI å·¥å…·** - å‘½ä»¤è¡Œäº¤äº’ç•Œé¢
- ğŸš€ **CPU å‹å¥½** - æ— éœ€ NVIDIA GPU å³å¯è¿è¡Œ

## é¡¹ç›®ç»“æ„

```
XAIChat/
â”œâ”€â”€ cli/                    # å‘½ä»¤è¡Œç•Œé¢
â”‚   â””â”€â”€ main.py            # CLI å…¥å£
â”œâ”€â”€ core/                   # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ config.py          # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ qwen_chat.py       # æ–‡æœ¬å¯¹è¯æ ¸å¿ƒ
â”‚   â”œâ”€â”€ qwen_vision.py     # å›¾åƒç†è§£æ ¸å¿ƒ
â”‚   â””â”€â”€ text2img.py        # æ–‡ç”Ÿå›¾æ ¸å¿ƒ
â”œâ”€â”€ server/                 # Web API æœåŠ¡
â”‚   â”œâ”€â”€ main.py            # FastAPI å…¥å£
â”‚   â”œâ”€â”€ routers/           # API è·¯ç”±
â”‚   â”‚   â”œâ”€â”€ chat.py        # å¯¹è¯ API
â”‚   â”‚   â”œâ”€â”€ vision.py      # å›¾åƒç†è§£ API
â”‚   â”‚   â””â”€â”€ image.py       # æ–‡ç”Ÿå›¾ API
â”‚   â””â”€â”€ services/          # ä¸šåŠ¡é€»è¾‘
â”œâ”€â”€ web/                    # React å‰ç«¯
â”œâ”€â”€ models/                 # æ¨¡å‹æ–‡ä»¶ç›®å½•
â”œâ”€â”€ start_local.sh         # CLI å¯åŠ¨è„šæœ¬
â””â”€â”€ start_web.sh           # Web æœåŠ¡å¯åŠ¨è„šæœ¬
```

## ç¯å¢ƒè¦æ±‚

- Python >= 3.8
- Node.js >= 18ï¼ˆWeb ç•Œé¢éœ€è¦ï¼‰
- RAM >= 8GBï¼ˆæ¨è 16GBï¼‰
- å¯é€‰: NVIDIA GPUï¼ˆå¯åŠ é€Ÿæ¨ç†ï¼‰

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# Python ä¾èµ–
pip install -r requirements.txt

# å‰ç«¯ä¾èµ–ï¼ˆå¯é€‰ï¼Œä½¿ç”¨ Web ç•Œé¢æ—¶éœ€è¦ï¼‰
cd web && npm install && cd ..
```

> **æ³¨æ„**: å¦‚æœå®‰è£… `llama-cpp-python` æ—¶é‡åˆ°é—®é¢˜ï¼š
> ```bash
> # CPU ç‰ˆæœ¬
> pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu
> ```

### 2. é…ç½®ï¼ˆå¯é€‰ï¼‰

å¤åˆ¶é…ç½®æ¨¡æ¿å¹¶æ ¹æ®éœ€è¦ä¿®æ”¹ï¼š

```bash
cp .env.template .env
```

ä¸»è¦é…ç½®é¡¹ï¼š

| é…ç½®é¡¹ | è¯´æ˜ | é»˜è®¤å€¼ |
|--------|------|--------|
| `QWEN_CHAT_MODEL_ID` | Chat æ¨¡å‹ HuggingFace ID | `unsloth/Qwen3-1.7B-GGUF` |
| `QWEN_CHAT_MODEL_FILENAME` | GGUF æ–‡ä»¶å | `Qwen3-1.7B-Q4_K_M.gguf` |
| `QWEN_CHAT_CONTEXT_LENGTH` | ä¸Šä¸‹æ–‡çª—å£å¤§å° | `8192` |
| `QWEN_HF_ENDPOINT` | HuggingFace é•œåƒåœ°å€ | `https://hf-mirror.com` |

### 3. ä¸‹è½½æ¨¡å‹

æ¨¡å‹ä¼šåœ¨é¦–æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨ä» HuggingFace ä¸‹è½½ã€‚ä¹Ÿå¯ä»¥æ‰‹åŠ¨ä¸‹è½½ï¼š

| æ¨¡å‹ | å¤§å° | å†…å­˜éœ€æ±‚ | é“¾æ¥ |
|------|------|----------|------|
| Qwen3-1.7B Q4_K_M | ~1.1GB | ~4GB | [ä¸‹è½½](https://huggingface.co/unsloth/Qwen3-1.7B-GGUF) |
| Qwen3-4B Q4_K_M | ~2.5GB | ~6GB | [ä¸‹è½½](https://huggingface.co/unsloth/Qwen3-4B-GGUF) |
| Qwen3-8B Q4_K_M | ~4.5GB | ~8GB | [ä¸‹è½½](https://huggingface.co/unsloth/Qwen3-8B-GGUF) |

ä¸‹è½½åå°† `.gguf` æ–‡ä»¶æ”¾åˆ° `./models/` ç›®å½•ã€‚

## ä½¿ç”¨æ–¹æ³•

### æ–¹å¼ä¸€ï¼šWeb ç•Œé¢ï¼ˆæ¨èï¼‰

```bash
# å¯åŠ¨å®Œæ•´ Web åº”ç”¨ï¼ˆå‰åç«¯ï¼‰
./start_web.sh

# æˆ–åˆ†åˆ«å¯åŠ¨
./start_web.sh backend   # ä»…åç«¯ API
./start_web.sh frontend  # ä»…å‰ç«¯ç•Œé¢
```

æœåŠ¡å¯åŠ¨åè®¿é—®ï¼š
- **å‰ç«¯ç•Œé¢**: http://localhost:5173
- **API æ–‡æ¡£**: http://localhost:8000/docs
- **å¥åº·æ£€æŸ¥**: http://localhost:8000/health

### æ–¹å¼äºŒï¼šå‘½ä»¤è¡Œç•Œé¢

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®å¯åŠ¨ï¼ˆè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼‰
./start_local.sh

# æˆ–ç›´æ¥è¿è¡Œ
python -m cli.main

# æŒ‡å®šæœ¬åœ°æ¨¡å‹
python -m cli.main --model ./models/custom-model.gguf

# å¯åŠ¨æ—¶åŠ è½½å›¾ç‰‡è¿›è¡Œè§†è§‰é—®ç­”
python -m cli.main --input-image ./photo.jpg
```

### æ–¹å¼ä¸‰ï¼šç›´æ¥è°ƒç”¨ API

```bash
# å¯¹è¯
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "ä½ å¥½", "enable_thinking": true}'

# å›¾åƒç†è§£
curl -X POST http://localhost:8000/api/vision/analyze \
  -F "file=@./image.jpg" \
  -F "prompt=æè¿°è¿™å¼ å›¾ç‰‡"

# æ–‡ç”Ÿå›¾
curl -X POST http://localhost:8000/api/image/generate \
  -H "Content-Type: application/json" \
  -d '{"prompt": "a cute cat"}'
```

## CLI å‘½ä»¤å‚æ•°

| å‚æ•° | ç®€å†™ | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|------|--------|
| `--model` | `-m` | GGUF æ¨¡å‹è·¯å¾„ | é…ç½®æ–‡ä»¶ |
| `--ctx` | `-c` | ä¸Šä¸‹æ–‡çª—å£å¤§å° | 8192 |
| `--threads` | `-t` | CPU çº¿ç¨‹æ•° | auto |
| `--gpu-layers` | `-g` | GPU å±‚æ•°ï¼ˆéœ€ CUDAï¼‰ | 0 |
| `--input-image` | `-i` | å¯åŠ¨æ—¶åŠ è½½çš„å›¾ç‰‡ | - |
| `--no-vision` | - | ç¦ç”¨å›¾åƒç†è§£ | false |
| `--no-image` | - | ç¦ç”¨æ–‡ç”Ÿå›¾ | false |
| `--verbose` | `-v` | æ˜¾ç¤ºè¯¦ç»†æ—¥å¿— | false |

## CLI äº¤äº’å‘½ä»¤

| å‘½ä»¤ | è¯´æ˜ |
|------|------|
| `/quit` æˆ– `/exit` | é€€å‡ºç¨‹åº |
| `/clear` | æ¸…ç©ºå¯¹è¯å†å² |
| `/help` | æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯ |
| `/history` | æŸ¥çœ‹å¯¹è¯å†å² |

## API ç«¯ç‚¹

| ç«¯ç‚¹ | æ–¹æ³• | è¯´æ˜ |
|------|------|------|
| `/api/chat` | POST | æ–‡æœ¬å¯¹è¯ï¼ˆæ”¯æŒæµå¼ï¼‰ |
| `/api/vision/analyze` | POST | å›¾åƒç†è§£åˆ†æ |
| `/api/image/generate` | POST | æ–‡ç”Ÿå›¾ |
| `/health` | GET | å¥åº·æ£€æŸ¥ |
| `/docs` | GET | Swagger API æ–‡æ¡£ |

## æ€§èƒ½ä¼˜åŒ–

### å†…å­˜ä¸è¶³æ—¶
1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚ Qwen3-1.7Bï¼‰
2. å‡å°ä¸Šä¸‹æ–‡çª—å£ï¼š`--ctx 2048`
3. é™åˆ¶çº¿ç¨‹æ•°ï¼š`--threads 4`

### æƒ³è¦æ›´å¿«é€Ÿåº¦
1. å¢åŠ çº¿ç¨‹æ•°ï¼ˆä¸è¶…è¿‡ CPU æ ¸å¿ƒæ•°ï¼‰
2. å¦‚æœæœ‰ NVIDIA GPUï¼Œä½¿ç”¨ `--gpu-layers` å‚æ•°

## æ•…éšœæ’é™¤

### llama-cpp-python å®‰è£…å¤±è´¥
```bash
# å°è¯•å®‰è£…é¢„ç¼–è¯‘ç‰ˆæœ¬
pip install llama-cpp-python --prefer-binary

# æˆ–è€…ä½¿ç”¨ conda
conda install -c conda-forge llama-cpp-python
```

### æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼ˆ404 é”™è¯¯ï¼‰
æ£€æŸ¥æ¨¡å‹ ID æ˜¯å¦æ­£ç¡®ï¼Œæ¨èä½¿ç”¨ `unsloth/Qwen3-1.7B-GGUF` ä»“åº“ã€‚

### æ¨¡å‹åŠ è½½å¤±è´¥
ç¡®ä¿ï¼š
1. æ¨¡å‹æ–‡ä»¶å®Œæ•´ä¸‹è½½ï¼ˆæ£€æŸ¥æ–‡ä»¶å¤§å°ï¼‰
2. æ¨¡å‹æ ¼å¼ä¸º GGUFï¼ˆä¸æ˜¯ safetensors æˆ– binï¼‰
3. æœ‰è¶³å¤Ÿçš„å†…å­˜åŠ è½½æ¨¡å‹

### å·²çŸ¥è­¦å‘Šä¿¡æ¯

#### âš ï¸ Qwen2VLRotaryEmbedding è­¦å‘Š
```
`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config
through the `config` argument. All other arguments will be removed in v4.46
```

**è¯´æ˜**ï¼š
- è¿™æ˜¯ `transformers` åº“å†…éƒ¨çš„ API å˜æ›´æç¤ºï¼Œ**ä¸æ˜¯æœ¬é¡¹ç›®çš„é—®é¢˜**
- æ¥è‡ª Hugging Face å®˜æ–¹çš„ Qwen2-VL æ¨¡å‹å®ç°ä»£ç 
- **å®Œå…¨ä¸å½±å“åŠŸèƒ½**ï¼Œæ¨¡å‹å¯ä»¥æ­£å¸¸å·¥ä½œ
- å°†åœ¨ `transformers>=4.46` ç‰ˆæœ¬ä¸­ç”±å®˜æ–¹ä¿®å¤

**å¤„ç†æ–¹å¼**ï¼š
- âœ… **æ¨è**ï¼šæš‚æ—¶å¿½ç•¥ï¼Œä¸å½±å“ä½¿ç”¨
- ğŸ”„ **æœªæ¥**ï¼šç­‰ transformers v4.46+ å‘å¸ƒåæ‰§è¡Œ `pip install transformers>=4.46 --upgrade`

#### âœ… NVML åˆå§‹åŒ–è­¦å‘Šï¼ˆå·²è§£å†³ï¼‰
```
Can't initialize NVML
```

**è¯´æ˜**ï¼š
- æœ¬é¡¹ç›®å·²é€šè¿‡è®¾ç½® `CUDA_VISIBLE_DEVICES=""` ç¯å¢ƒå˜é‡è§£å†³
- æ‰€æœ‰æ¨¡å‹å¼ºåˆ¶ä½¿ç”¨ CPU æ¨¡å¼ï¼Œé¿å… CUDA/NVML åˆå§‹åŒ–
- å¦‚æœä»ç„¶çœ‹åˆ°æ­¤è­¦å‘Šï¼Œè¯·æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æœ€æ–°ä»£ç 

#### âš ï¸ Safety Checker è­¦å‘Šï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
```
You have disabled the safety checker for <LatentConsistencyModelPipeline> by passing `safety_checker=None`.
```

**è¯´æ˜**ï¼š
- æœ¬é¡¹ç›®ä¸ºäº†æå‡ CPU æ¨ç†æ€§èƒ½ï¼Œé»˜è®¤ç¦ç”¨äº† Stable Diffusion çš„å®‰å…¨æ£€æŸ¥å™¨
- Safety Checker ä¼šå ç”¨é¢å¤–å†…å­˜å¹¶é™ä½ç”Ÿæˆé€Ÿåº¦ï¼ˆçº¦ 30-40%ï¼‰
- è¿™æ˜¯**æœ‰æ„çš„æ€§èƒ½ä¼˜åŒ–**ï¼Œé€‚ç”¨äºä¸ªäººä½¿ç”¨å’Œå†…éƒ¨é¡¹ç›®

**ä½¿ç”¨å»ºè®®**ï¼š
- âœ… **ä¸ªäºº/å†…éƒ¨ä½¿ç”¨**ï¼šä¿æŒç¦ç”¨çŠ¶æ€ï¼Œäº«å—æ›´å¿«çš„ç”Ÿæˆé€Ÿåº¦
- âš ï¸ **å…¬å¼€æœåŠ¡**ï¼šå»ºè®®å¯ç”¨ Safety Checkerï¼Œç¡®ä¿åˆè§„æ€§
  - ä¿®æ”¹ `core/text2img.py:133`ï¼Œç§»é™¤ `safety_checker=None` å‚æ•°
  - éµå®ˆ [Stable Diffusion è®¸å¯è¯](https://huggingface.co/spaces/CompVis/stable-diffusion-license)æ¡æ¬¾
- ğŸ“‹ ç”¨æˆ·éœ€è¦å¯¹ç”Ÿæˆçš„å†…å®¹æ‰¿æ‹…è´£ä»»

## æ–‡æ¡£

### ğŸ“š å®Œæ•´æ–‡æ¡£

| æ–‡æ¡£ | è¯´æ˜ |
|------|------|
| [API ä½¿ç”¨æ–‡æ¡£](docs/api-usage.md) | è¯¦ç»†çš„ API ç«¯ç‚¹è¯´æ˜ã€è¯·æ±‚ç¤ºä¾‹å’Œæœ€ä½³å®è·µ |
| [éƒ¨ç½²æŒ‡å—](docs/deployment-guide.md) | ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æ–¹æ¡ˆï¼ˆDockerã€Nginxã€Systemdï¼‰ |
| [æ•…éšœæ’æŸ¥æ‰‹å†Œ](docs/troubleshooting.md) | å¸¸è§é—®é¢˜è¯Šæ–­å’Œè§£å†³æ–¹æ¡ˆ |
| [æ€§èƒ½ä¼˜åŒ–æŒ‡å—](docs/performance-optimization.md) | CPU æ¨ç†æ€§èƒ½ä¼˜åŒ–æŠ€å·§ |
| [GGUF é‡åŒ–æŒ‡å—](docs/gguf-quantization-guide.md) | æ¨¡å‹é‡åŒ–åŸç†å’Œè‡ªå®šä¹‰é‡åŒ–æ–¹æ³• |

### ğŸ”— å¿«é€Ÿé“¾æ¥

- **API äº¤äº’å¼æ–‡æ¡£**: http://localhost:8000/docs
- **å¥åº·æ£€æŸ¥**: http://localhost:8000/health
- **é—®é¢˜åé¦ˆ**: [GitHub Issues](https://github.com/yourname/XAIChat/issues)
- **è®¨è®ºåŒº**: [GitHub Discussions](https://github.com/yourname/XAIChat/discussions)

## License

Apache License 2.0

---

Generated with â¤ï¸ by Harei-chan (ï¿£â–½ï¿£)ãƒ
